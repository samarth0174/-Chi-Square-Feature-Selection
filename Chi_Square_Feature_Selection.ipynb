{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Chi-Square Feature Selection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMvtjw6x8LK9Mv7iw8p1CI1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samarth0174/-Chi-Square-Feature-Selection/blob/master/Chi_Square_Feature_Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcTKleOP3Y5E",
        "colab_type": "text"
      },
      "source": [
        "## **Feature selection is a process where you automatically select those features in your data that contribute most to the prediction variable or output in which you are interested. The benefits of performing feature selection before modeling your data are:**\n",
        "\n",
        "* Avoid Overfitting: Less redundant data gives performance boost to the model and results in less opportunity to make decisions based on noise\n",
        "* Reduces Training Time: Less data means that algorithms train faster\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfOBjpLPVw5f",
        "colab_type": "text"
      },
      "source": [
        "## \n",
        "* One common feature selection method that is used with text data is the Chi-Square feature selection. \n",
        "* The χ2 test is used in statistics to test the independence of two events.  \n",
        "* More specifically in feature selection we use it to test whether the occurrence of a specific term and the occurrence of a specific class are independent. \n",
        "\n",
        "* For each feature (term), a corresponding high χ2 score indicates that the null hypothesis H0 of independence (meaning the document class has no influence over the term's frequency) should be rejected and the occurrence of the term and class are dependent. \n",
        "* In this case, we should select the feature for the text classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBJkpANQRKWr",
        "colab_type": "text"
      },
      "source": [
        "# **Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LfLoq9u2sB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: import pandas,numpy,labelbinarizer,selectkbest,countvectorizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5ABUJhARSOV",
        "colab_type": "text"
      },
      "source": [
        "# **For the given Dummy dataset you need to perform feature selection.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXjnRF8H4sj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array(['call you tonight', 'Call me a cab', 'please call me... PLEASE!', 'he will call me'])\n",
        "y = [1, 1, 2, 0] #class labels\n",
        "\n",
        "#TODO:convert it to a dense document-term matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "achXHlH6WUBv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7DUBQkWRrh8",
        "colab_type": "text"
      },
      "source": [
        "# **STEPS¶**\n",
        "* First compute the observed count for each class. This is done by building a contingency table from an input X (feature values) and y (class labels). \n",
        "*  Each entry i, j corresponds to some feature i and some class j, and holds the sum of the ith feature's values across all samples belonging to the class j.\n",
        "\n",
        "* Note that although the feature values here are represented as frequencies, this method also works quite well in practice when the values are tf-idf values, since those are just weighted/scaled frequencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhQuNRSDRqsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO : # binarize the output column,\n",
        "#observed count for each class (the row)\n",
        "# and each feature (the column)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcwVOR9mSBrc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO : # compute the probability of each class and the feature count; \n",
        "# keep both as a 2 dimension array using reshape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh7uLCqoSQOB",
        "colab_type": "text"
      },
      "source": [
        "### **We can do chi square test with an assumption that there is no biase between the columns. We can also do Chi_square test directly from the contigency table** \n",
        "\n",
        "### **find the Chi value and P value for each feature**\n",
        "* chi-square scores - the scores are better if greater. \n",
        "* p-values - they are better if smaller.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiENIGrwSDAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO : Find chisqscore for each feature value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB40iZxpSWT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO : Cross check the same using Scikit learn chi2 function**"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjFUJRlFcct_",
        "colab_type": "text"
      },
      "source": [
        "# **Feature Selection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Usuihe_Xbnqc",
        "colab_type": "text"
      },
      "source": [
        "## **Select k best features using Chisquare as score fn**\n",
        "**Scikit**-**learn** provides a **SelectKBest** class that can be used with a suite of different statistical tests. It will rank the features with the statistical test that we've specified and select the top k performing ones (meaning that these terms is considered to be more relevant to the task at hand than the others), where k is also a number that we can tweak."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEIyB_6SbiCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO : scikit selectkbest"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO36-MN_cmik",
        "colab_type": "text"
      },
      "source": [
        "# **Conclusion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQruTfQkfvn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}